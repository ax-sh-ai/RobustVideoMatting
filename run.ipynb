{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7913f96-73c5-4daa-bd28-c9624b01462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version        \n",
      "------------------------- ---------------\n",
      "anyio                     4.3.0          \n",
      "argon2-cffi               23.1.0         \n",
      "argon2-cffi-bindings      21.2.0         \n",
      "arrow                     1.3.0          \n",
      "asttokens                 2.4.1          \n",
      "async-lru                 2.0.4          \n",
      "attrs                     23.2.0         \n",
      "av                        11.0.0         \n",
      "babel                     2.14.0         \n",
      "beautifulsoup4            4.12.3         \n",
      "bleach                    6.1.0          \n",
      "certifi                   2024.2.2       \n",
      "cffi                      1.16.0         \n",
      "charset-normalizer        3.3.2          \n",
      "colorama                  0.4.6          \n",
      "comm                      0.2.1          \n",
      "debugpy                   1.8.1          \n",
      "decorator                 5.1.1          \n",
      "defusedxml                0.7.1          \n",
      "executing                 2.0.1          \n",
      "fastjsonschema            2.19.1         \n",
      "filelock                  3.9.0          \n",
      "fqdn                      1.5.1          \n",
      "fsspec                    2023.4.0       \n",
      "h11                       0.14.0         \n",
      "httpcore                  1.0.4          \n",
      "httpx                     0.27.0         \n",
      "idna                      3.6            \n",
      "imageio                   2.34.0         \n",
      "ipykernel                 6.29.3         \n",
      "ipython                   8.22.2         \n",
      "isoduration               20.11.0        \n",
      "jedi                      0.19.1         \n",
      "jinja2                    3.1.2          \n",
      "json5                     0.9.22         \n",
      "jsonpointer               2.4            \n",
      "jsonschema                4.21.1         \n",
      "jsonschema-specifications 2023.12.1      \n",
      "jupyter-client            8.6.0          \n",
      "jupyter-core              5.7.1          \n",
      "jupyter-events            0.9.0          \n",
      "jupyter-lsp               2.2.4          \n",
      "jupyter-server            2.13.0         \n",
      "jupyter-server-terminals  0.5.2          \n",
      "jupyterlab                4.1.4          \n",
      "jupyterlab-pygments       0.3.0          \n",
      "jupyterlab-server         2.25.3         \n",
      "markupsafe                2.1.3          \n",
      "matplotlib-inline         0.1.6          \n",
      "mistune                   3.0.2          \n",
      "mpmath                    1.3.0          \n",
      "nbclient                  0.9.0          \n",
      "nbconvert                 7.16.2         \n",
      "nbformat                  5.9.2          \n",
      "nest-asyncio              1.6.0          \n",
      "networkx                  3.2.1          \n",
      "notebook-shim             0.2.4          \n",
      "numpy                     1.26.3         \n",
      "overrides                 7.7.0          \n",
      "packaging                 23.2           \n",
      "pandocfilters             1.5.1          \n",
      "parso                     0.8.3          \n",
      "pillow                    10.2.0         \n",
      "pims                      0.6.1          \n",
      "platformdirs              4.2.0          \n",
      "prometheus-client         0.20.0         \n",
      "prompt-toolkit            3.0.43         \n",
      "psutil                    5.9.8          \n",
      "pure-eval                 0.2.2          \n",
      "pycparser                 2.21           \n",
      "pygments                  2.17.2         \n",
      "python-dateutil           2.9.0.post0    \n",
      "python-json-logger        2.0.7          \n",
      "pywin32                   306            \n",
      "pywinpty                  2.0.13         \n",
      "pyyaml                    6.0.1          \n",
      "pyzmq                     25.1.2         \n",
      "referencing               0.33.0         \n",
      "requests                  2.31.0         \n",
      "rfc3339-validator         0.1.4          \n",
      "rfc3986-validator         0.1.1          \n",
      "rpds-py                   0.18.0         \n",
      "send2trash                1.8.2          \n",
      "six                       1.16.0         \n",
      "slicerator                1.1.0          \n",
      "sniffio                   1.3.1          \n",
      "soupsieve                 2.5            \n",
      "stack-data                0.6.3          \n",
      "sympy                     1.12           \n",
      "terminado                 0.18.0         \n",
      "tinycss2                  1.2.1          \n",
      "torch                     2.2.1+cu121    \n",
      "torchaudio                2.2.1+cu121    \n",
      "torchvision               0.17.1+cu121   \n",
      "tornado                   6.4            \n",
      "tqdm                      4.66.2         \n",
      "traitlets                 5.14.1         \n",
      "types-python-dateutil     2.8.19.20240106\n",
      "typing-extensions         4.8.0          \n",
      "uri-template              1.3.0          \n",
      "urllib3                   2.2.1          \n",
      "wcwidth                   0.2.13         \n",
      "webcolors                 1.13           \n",
      "webencodings              0.5.1          \n",
      "websocket-client          1.7.0          \n"
     ]
    }
   ],
   "source": [
    "!uv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7ccff4b-73f0-408a-ba5e-a5c580ca15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import MattingNetwork\n",
    "\n",
    "model = MattingNetwork('mobilenetv3').eval().cuda()  # or \"resnet50\"\n",
    "model.load_state_dict(torch.load('rvm_mobilenetv3.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "855e1b10-769a-4ced-9e52-aaed63a3eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Desktop\\lab\\RobustVideoMatting\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|                                                                              | 12/7508 [00:17<3:01:46,  1.46s/it]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 11.99 GiB of which 0 bytes is free. Of the allocated memory 10.02 GiB is allocated by PyTorch, and 919.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_video\n\u001b[0;32m      2\u001b[0m input_source\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo.webm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mconvert_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                           \u001b[49m\u001b[38;5;66;43;03m# The model, can be on any device (cpu or cuda).\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# A video file or an image sequence directory.\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvideo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Choose \"video\" or \"png_sequence\"\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_composition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcom.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# File path if video; directory path if png sequence.\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# [Optional] Output the raw alpha prediction.\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_foreground\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfgr.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# [Optional] Output the raw foreground prediction.\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_video_mbps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Output video mbps. Not needed for png sequence.\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownsample_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# A hyperparameter to adjust or use None for auto.\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseq_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Process n frames at once for better parallelism.\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\inference.py:127\u001b[0m, in \u001b[0;36mconvert_video\u001b[1;34m(model, input_source, input_resize, downsample_ratio, output_type, output_composition, output_alpha, output_foreground, output_video_mbps, seq_chunk, num_workers, progress, device, dtype)\u001b[0m\n\u001b[0;32m    124\u001b[0m     downsample_ratio \u001b[38;5;241m=\u001b[39m auto_downsample_ratio(\u001b[38;5;241m*\u001b[39msrc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m    126\u001b[0m src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device, dtype, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# [B, T, C, H, W]\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m fgr, pha, \u001b[38;5;241m*\u001b[39mrec \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsample_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_foreground \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     writer_fgr\u001b[38;5;241m.\u001b[39mwrite(fgr[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\model\\model.py:61\u001b[0m, in \u001b[0;36mMattingNetwork.forward\u001b[1;34m(self, src, r1, r2, r3, r4, downsample_ratio, segmentation_pass)\u001b[0m\n\u001b[0;32m     59\u001b[0m fgr_residual, pha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject_mat(hid)\u001b[38;5;241m.\u001b[39msplit([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m downsample_ratio \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 61\u001b[0m     fgr_residual, pha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefiner\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_sm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfgr_residual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m fgr \u001b[38;5;241m=\u001b[39m fgr_residual \u001b[38;5;241m+\u001b[39m src\n\u001b[0;32m     63\u001b[0m fgr \u001b[38;5;241m=\u001b[39m fgr\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m1.\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\model\\deep_guided_filter.py:59\u001b[0m, in \u001b[0;36mDeepGuidedFilterRefiner.forward\u001b[1;34m(self, fine_src, base_src, base_fgr, base_pha, base_hid)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, fine_src, base_src, base_fgr, base_pha, base_hid):\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fine_src\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_fgr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_pha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_hid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_single_frame(fine_src, base_src, base_fgr, base_pha, base_hid)\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\model\\deep_guided_filter.py:47\u001b[0m, in \u001b[0;36mDeepGuidedFilterRefiner.forward_time_series\u001b[1;34m(self, fine_src, base_src, base_fgr, base_pha, base_hid)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_time_series\u001b[39m(\u001b[38;5;28mself\u001b[39m, fine_src, base_src, base_fgr, base_pha, base_hid):\n\u001b[0;32m     46\u001b[0m     B, T \u001b[38;5;241m=\u001b[39m fine_src\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m---> 47\u001b[0m     fgr, pha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_single_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfine_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_src\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_fgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_pha\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_hid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     fgr \u001b[38;5;241m=\u001b[39m fgr\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m0\u001b[39m, (B, T))\n\u001b[0;32m     54\u001b[0m     pha \u001b[38;5;241m=\u001b[39m pha\u001b[38;5;241m.\u001b[39munflatten(\u001b[38;5;241m0\u001b[39m, (B, T))\n",
      "File \u001b[1;32m~\\Desktop\\lab\\RobustVideoMatting\\model\\deep_guided_filter.py:41\u001b[0m, in \u001b[0;36mDeepGuidedFilterRefiner.forward_single_frame\u001b[1;34m(self, fine_src, base_src, base_fgr, base_pha, base_hid)\u001b[0m\n\u001b[0;32m     38\u001b[0m A \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(A, (H, W), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m b \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(b, (H, W), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 41\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfine_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m     42\u001b[0m fgr, pha \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39msplit([\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fgr, pha\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.48 GiB. GPU 0 has a total capacity of 11.99 GiB of which 0 bytes is free. Of the allocated memory 10.02 GiB is allocated by PyTorch, and 919.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from inference import convert_video\n",
    "input_source= 'video.webm'\n",
    "convert_video(\n",
    "    model,                           # The model, can be on any device (cpu or cuda).\n",
    "    input_source=input_source,        # A video file or an image sequence directory.\n",
    "    output_type='video',             # Choose \"video\" or \"png_sequence\"\n",
    "    output_composition='com.mp4',    # File path if video; directory path if png sequence.\n",
    "    output_alpha=\"mask.mp4\",          # [Optional] Output the raw alpha prediction.\n",
    "    output_foreground=\"fgr.mp4\",     # [Optional] Output the raw foreground prediction.\n",
    "    output_video_mbps=4,             # Output video mbps. Not needed for png sequence.\n",
    "    downsample_ratio=None,           # A hyperparameter to adjust or use None for auto.\n",
    "    seq_chunk=12,                    # Process n frames at once for better parallelism.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f396c-cb3f-4834-86d1-006656265aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
